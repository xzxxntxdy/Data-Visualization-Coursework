"""
ç©ºé—´æ•°æ®å¤„ç†è„šæœ¬ - ä» COCO instances æå– bbox ä¿¡æ¯
ç”Ÿæˆç”¨äºç©ºé—´/å°ºåº¦åˆ†æçš„ JSON æ•°æ®æ–‡ä»¶

è¾“å‡ºæ•°æ®ç»“æ„ï¼š
- spatial_data.json: åŒ…å«é‡‡æ ·çš„æ ‡æ³¨æ•°æ®ã€ç±»åˆ«ç»Ÿè®¡ã€ç©ºé—´ç½‘æ ¼èšåˆ
"""

import json
import os
import random
from collections import defaultdict
import math

DATA_DIR = os.path.join("src", "data")
INPUT_FILE = os.path.join(DATA_DIR, "instances_train2017.json")
OUTPUT_FILE = os.path.join(DATA_DIR, "spatial_data.json")

# é‡‡æ ·æ•°é‡ï¼šæ§åˆ¶å‰ç«¯æ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯ä»£è¡¨æ€§
SAMPLE_SIZE = 8000
# ç©ºé—´ç½‘æ ¼åˆ†è¾¨ç‡ (ç”¨äºçƒ­åŠ›å›¾é¢„èšåˆ)
GRID_SIZE = 20

# COCO å®˜æ–¹å°ºåº¦é˜ˆå€¼ (åƒç´ é¢ç§¯)
SCALE_THRESHOLDS = {
    "small": 32 * 32,      # < 1024
    "medium": 96 * 96,     # 1024 ~ 9216
    "large": float("inf")  # > 9216
}


def get_scale_category(area):
    """æ ¹æ® COCO å®˜æ–¹æ ‡å‡†åˆ’åˆ†ç›®æ ‡å°ºåº¦"""
    if area < SCALE_THRESHOLDS["small"]:
        return "small"
    elif area < SCALE_THRESHOLDS["medium"]:
        return "medium"
    else:
        return "large"


def process_spatial_data():
    print(f"ğŸ“‚ Loading data from {INPUT_FILE}...")
    
    try:
        with open(INPUT_FILE, "r", encoding="utf-8") as f:
            coco_data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ Error: {INPUT_FILE} not found.")
        print("Please place instances_train2017.json in src/data/")
        return

    # æ„å»ºç±»åˆ«æ˜ å°„
    categories = {cat["id"]: cat["name"] for cat in coco_data["categories"]}
    # æ„å»ºè¶…ç±»æ˜ å°„ (COCO 80ç±» -> 12ä¸ªè¶…ç±»)
    supercategories = {cat["id"]: cat.get("supercategory", "other") 
                       for cat in coco_data["categories"]}
    
    # æ„å»ºå›¾åƒå°ºå¯¸æ˜ å°„
    image_dims = {img["id"]: (img["width"], img["height"]) 
                  for img in coco_data["images"]}
    
    print(f"âœ… Loaded {len(categories)} categories, {len(image_dims)} images")
    
    annotations = coco_data["annotations"]
    print(f"ğŸ“Š Total annotations: {len(annotations)}")
    
    # ========== 1. å¤„ç†æ‰€æœ‰æ ‡æ³¨ï¼Œè®¡ç®—å½’ä¸€åŒ–åæ ‡ ==========
    processed_anns = []
    category_stats = defaultdict(lambda: {
        "count": 0,
        "areas": [],
        "aspect_ratios": [],
        "scale_dist": {"small": 0, "medium": 0, "large": 0}
    })
    
    # ç©ºé—´ç½‘æ ¼è®¡æ•° (æŒ‰ç±»åˆ«)
    spatial_grids = defaultdict(lambda: [[0] * GRID_SIZE for _ in range(GRID_SIZE)])
    global_grid = [[0] * GRID_SIZE for _ in range(GRID_SIZE)]
    
    for ann in annotations:
        img_id = ann["image_id"]
        cat_id = ann["category_id"]
        bbox = ann["bbox"]  # [x, y, width, height]
        area = ann.get("area", bbox[2] * bbox[3])
        
        if img_id not in image_dims:
            continue
            
        img_w, img_h = image_dims[img_id]
        if img_w <= 0 or img_h <= 0:
            continue
        
        # è®¡ç®—å½’ä¸€åŒ–ä¸­å¿ƒåæ ‡ (0~1)
        cx = (bbox[0] + bbox[2] / 2) / img_w
        cy = (bbox[1] + bbox[3] / 2) / img_h
        
        # å½’ä¸€åŒ–å®½é«˜
        norm_w = bbox[2] / img_w
        norm_h = bbox[3] / img_h
        
        # ç›¸å¯¹é¢ç§¯ (å å›¾åƒé¢ç§¯çš„æ¯”ä¾‹)
        rel_area = (bbox[2] * bbox[3]) / (img_w * img_h)
        
        # å®½é«˜æ¯”
        aspect_ratio = bbox[2] / max(bbox[3], 1)
        
        # å°ºåº¦åˆ†ç±»
        scale_cat = get_scale_category(area)
        
        # æ›´æ–°ç±»åˆ«ç»Ÿè®¡
        stats = category_stats[cat_id]
        stats["count"] += 1
        stats["areas"].append(rel_area)
        stats["aspect_ratios"].append(aspect_ratio)
        stats["scale_dist"][scale_cat] += 1
        
        # æ›´æ–°ç©ºé—´ç½‘æ ¼
        grid_x = min(int(cx * GRID_SIZE), GRID_SIZE - 1)
        grid_y = min(int(cy * GRID_SIZE), GRID_SIZE - 1)
        spatial_grids[cat_id][grid_y][grid_x] += 1
        global_grid[grid_y][grid_x] += 1
        
        # ä¿å­˜å¤„ç†åçš„æ ‡æ³¨
        processed_anns.append({
            "id": ann["id"],
            "image_id": img_id,
            "category_id": cat_id,
            "category": categories[cat_id],
            "supercategory": supercategories[cat_id],
            "cx": round(cx, 4),
            "cy": round(cy, 4),
            "width": round(norm_w, 4),
            "height": round(norm_h, 4),
            "area": round(rel_area, 6),
            "aspect_ratio": round(aspect_ratio, 3),
            "raw_area": area,
            "scale": scale_cat
        })
    
    print(f"âœ… Processed {len(processed_anns)} valid annotations")
    
    # ========== 2. éšæœºé‡‡æ ·ä»¥æ§åˆ¶å‰ç«¯æ•°æ®é‡ ==========
    print("ğŸ”„ Sampling annotations...")
    if len(processed_anns) > SAMPLE_SIZE:
        # åˆ†å±‚é‡‡æ ·ï¼šç¡®ä¿æ¯ä¸ªç±»åˆ«éƒ½æœ‰ä»£è¡¨
        sampled = []
        cats_list = list(category_stats.keys())
        per_cat = max(SAMPLE_SIZE // len(cats_list), 50)
        
        by_cat = defaultdict(list)
        for ann in processed_anns:
            by_cat[ann["category_id"]].append(ann)
        
        sampled_ids = set()
        for cat_id in cats_list:
            cat_anns = by_cat[cat_id]
            sample_n = min(len(cat_anns), per_cat)
            cat_sampled = random.sample(cat_anns, sample_n)
            sampled.extend(cat_sampled)
            for a in cat_sampled:
                sampled_ids.add(a["id"])
        
        # å¦‚æœè¿˜ä¸å¤Ÿï¼Œéšæœºè¡¥å……ï¼ˆä½¿ç”¨ set å¿«é€Ÿåˆ¤æ–­ï¼‰
        if len(sampled) < SAMPLE_SIZE:
            remaining = [a for a in processed_anns if a["id"] not in sampled_ids]
            extra = min(SAMPLE_SIZE - len(sampled), len(remaining))
            if extra > 0:
                sampled.extend(random.sample(remaining, extra))
        
        processed_anns = sampled[:SAMPLE_SIZE]
        print(f"ğŸ“‰ Sampled down to {len(processed_anns)} annotations")
    
    # ========== 3. è®¡ç®—ç±»åˆ«ç»Ÿè®¡æ‘˜è¦ ==========
    print("ğŸ“ˆ Computing category statistics...")
    category_summary = []
    for cat_id, stats in category_stats.items():
        if stats["count"] == 0:
            continue
        
        areas = stats["areas"]
        ratios = stats["aspect_ratios"]
        
        category_summary.append({
            "id": cat_id,
            "name": categories[cat_id],
            "supercategory": supercategories[cat_id],
            "count": stats["count"],
            "area_stats": {
                "mean": round(sum(areas) / len(areas), 6),
                "min": round(min(areas), 6),
                "max": round(max(areas), 6),
                "median": round(sorted(areas)[len(areas) // 2], 6)
            },
            "aspect_ratio_stats": {
                "mean": round(sum(ratios) / len(ratios), 3),
                "min": round(min(ratios), 3),
                "max": round(max(ratios), 3)
            },
            "scale_distribution": stats["scale_dist"]
        })
    
    # æŒ‰æ•°é‡æ’åº
    category_summary.sort(key=lambda x: -x["count"])
    
    # ========== 4. ç”Ÿæˆç©ºé—´ç½‘æ ¼æ•°æ® (Top 10 ç±»åˆ«) ==========
    top_categories = [c["id"] for c in category_summary[:10]]
    grid_data = {
        "global": global_grid,
        "by_category": {
            categories[cat_id]: spatial_grids[cat_id] 
            for cat_id in top_categories
        },
        "grid_size": GRID_SIZE
    }
    
    # ========== 5. ç”Ÿæˆå°ºåº¦åˆ†å¸ƒç›´æ–¹å›¾æ•°æ® ==========
    # å¯¹ log(area) åšåˆ†æ¡¶ç»Ÿè®¡
    def compute_histogram(values, bins=30):
        if not values:
            return []
        log_vals = [math.log10(max(v, 1e-8)) for v in values]
        min_v, max_v = min(log_vals), max(log_vals)
        if min_v == max_v:
            return [{"x": min_v, "count": len(values)}]
        
        bin_width = (max_v - min_v) / bins
        hist = [0] * bins
        for v in log_vals:
            idx = min(int((v - min_v) / bin_width), bins - 1)
            hist[idx] += 1
        
        return [
            {"x": round(min_v + (i + 0.5) * bin_width, 4), "count": c}
            for i, c in enumerate(hist) if c > 0
        ]
    
    scale_histograms = {}
    for cat in category_summary[:20]:  # Top 20 ç±»åˆ«çš„ç›´æ–¹å›¾
        cat_areas = [a["area"] for a in processed_anns if a["category_id"] == cat["id"]]
        scale_histograms[cat["name"]] = compute_histogram(cat_areas)
    
    # ========== 6. è¾“å‡ºæœ€ç»ˆæ•°æ® ==========
    output_data = {
        "annotations": processed_anns,
        "categories": category_summary,
        "spatial_grid": grid_data,
        "scale_histograms": scale_histograms,
        "meta": {
            "total_annotations": len(coco_data["annotations"]),
            "sampled_count": len(processed_anns),
            "grid_resolution": GRID_SIZE,
            "scale_thresholds": {
                "small": "< 32x32",
                "medium": "32x32 ~ 96x96",
                "large": "> 96x96"
            }
        }
    }
    
    print(f"ğŸ’¾ Saving to {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False)
    
    file_size = os.path.getsize(OUTPUT_FILE) / (1024 * 1024)
    print(f"âœ… Done! File size: {file_size:.2f} MB")
    print(f"   - {len(processed_anns)} sampled annotations")
    print(f"   - {len(category_summary)} categories with stats")
    print(f"   - {GRID_SIZE}x{GRID_SIZE} spatial grid")


if __name__ == "__main__":
    process_spatial_data()
